{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, label,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=label, yticklabels=label,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "features = ['Date', 'Payrolls_3mo_vs_12mo', 'Effective_Fed_Funds_12_chg', 'CPI_All_Items_3_mo_annualised',\n",
    "            '10Y_Treasury_Rate_12_chg', '3M_10Y_Treasury_Spread', 'S&P_500_Index_12_chg','Recession_in_6mo','Recession_in_12mo','Recession_in_24mo']\n",
    "df = pd.read_csv('/Users/sebin/Desktop/companyandngo/Data/final_features.csv')[::-1]\n",
    "predicted_probability=pd.DataFrame()\n",
    "past_predict = pd.DataFrame()\n",
    "test_prob = pd.DataFrame()\n",
    "recession_data = df[features]\n",
    "#df_features.join(pd.get_dummies(df['Recession']))\n",
    "output_feature =['Recession_in_6mo','Recession_in_12mo','Recession_in_24mo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_training_data=recession_data[recession_data['Date'] <= '2018-04-01']\n",
    "x_testing_data = recession_data[recession_data['Date'] >= '2018-04-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(x_training_data, x_training_data.iloc[:,7:], test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recession_in_6mo</th>\n",
       "      <th>Recession_in_12mo</th>\n",
       "      <th>Recession_in_24mo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>603 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recession_in_6mo  Recession_in_12mo  Recession_in_24mo\n",
       "616                 0                  1                  0\n",
       "394                 0                  0                  0\n",
       "298                 0                  0                  0\n",
       "179                 0                  0                  0\n",
       "775                 0                  0                  1\n",
       "..                ...                ...                ...\n",
       "642                 0                  0                  0\n",
       "474                 0                  1                  1\n",
       "477                 0                  1                  1\n",
       "277                 0                  0                  0\n",
       "660                 0                  0                  0\n",
       "\n",
       "[603 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state=88)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X_train.iloc[:,1:7], y_train['Recession_in_24mo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "models = [{'name': 'lg','label': 'Logistic Regression',\n",
    "           'classifier': LogisticRegression(random_state=88),\n",
    "           'grid': {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}},\n",
    "          \n",
    "          {'name': 'knn','label':'K Nearest Neighbors',\n",
    "           'classifier':KNeighborsClassifier(),\n",
    "           'grid': {\"n_neighbors\":np.arange(8)+1}},\n",
    "          {\n",
    "              'name':'xg','label':'xgboost','classifier':XGBClassifier(objective ='binary:logistic', learning_rate = 0.1,\n",
    "                 booster='gbtree',alpha = 10, n_estimators = 10),'grid':{\n",
    "                  'max_depth':range(3,10,1),\n",
    "                'gamma':[i/10.0 for i in range(0,5)],\n",
    "                 'colsample_bytree':[i/10.0 for i in range(1,10)],\n",
    "                 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05] \n",
    "              }\n",
    "          },\n",
    "          {'name': 'sv', 'label': 'SVC (RBF)',\n",
    "           'classifier':SVC(probability=True,\n",
    "                        tol=1e-3, random_state=123,\n",
    "                        class_weight='balanced'),\n",
    "           'grid': {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def model_selection(classifier, name, grid, X_train, y_train, scoring,i):\n",
    "    \n",
    "    gridsearch_cv=GridSearchCV(classifier, \n",
    "                               grid,\n",
    "                               cv=5, \n",
    "                               scoring = scoring,verbose=2,n_jobs=2)\n",
    "    \n",
    "    gridsearch_cv.fit(X_train, y_train)\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    results_dict['classifier_name'] = name    \n",
    "    results_dict['classifier'] = gridsearch_cv.best_estimator_\n",
    "    results_dict['best_params'] = gridsearch_cv.best_params_\n",
    "    results_dict['ROC_AUC'] = gridsearch_cv.best_score_\n",
    "    filename = i+'.'+name\n",
    "    pickle.dump(gridsearch_cv.best_estimator_, open(filename, 'wb'))\n",
    "    \n",
    "    return(results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lg\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  35 out of  35 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "knn\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "xg\n",
      "Fitting 5 folds for each of 1575 candidates, totalling 7875 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 501 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=2)]: Done 3405 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=2)]: Done 7875 out of 7875 | elapsed:   56.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "sv\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "lg\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  35 out of  35 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "knn\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  16 out of  40 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "xg\n",
      "Fitting 5 folds for each of 1575 candidates, totalling 7875 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 664 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=2)]: Done 3084 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=2)]: Done 7144 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=2)]: Done 7875 out of 7875 | elapsed:   56.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "sv\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "lg\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  35 out of  35 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "knn\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  16 out of  40 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "xg\n",
      "Fitting 5 folds for each of 1575 candidates, totalling 7875 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 862 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=2)]: Done 4008 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=2)]: Done 7875 out of 7875 | elapsed:   55.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "sv\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "for i in output_feature:\n",
    "    results = []\n",
    "    X_adasyn, y_adasyn = adasyn.fit_resample(X_train.iloc[:,1:7], y_train[i])\n",
    "    for m in models:  \n",
    "        print(m['name'])    \n",
    "        results.append(model_selection(m['classifier'], \n",
    "                                   m['name'],\n",
    "                                   m['grid'],\n",
    "                                   X_adasyn, \n",
    "                                   y_adasyn, \n",
    "                                   'roc_auc',i))      \n",
    "        print('completed')\n",
    "        results_df = pd.DataFrame(results).sort_values(by='ROC_AUC', ascending = False)\n",
    "        results_df.to_csv(i+'.csv',index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "roc_test=[]\n",
    "\n",
    "df = pd.read_csv(\"/Users/sebin/Desktop/companyandngo/src/Models/Recession_in_24mo.csv\")\n",
    "classifier = df['classifier'].to_list() \n",
    "\n",
    "for i in classifier:\n",
    "    X_adasyn, y_adasyn = adasyn.fit_resample(X_train.iloc[:,1:7], y_train['Recession_in_6mo'])\n",
    "    s=eval(i).fit(X_adasyn,y_adasyn)\n",
    "    pp=s.predict_proba(X_test.iloc[:,1:7])\n",
    "    score = roc_auc_score(y_test, pp)\n",
    "    roc_test.append(score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/sebin/Desktop/companyandngo/src/Models/Recession_in_24mo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['classifier_name', 'classifier', 'best_params', 'ROC_AUC',\n",
       "       'test_ROC_AUC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "l = results[0].get('classifier').predict_proba(X_test.iloc[:,1:7])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(testy, ns_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf'],'probability':[True],'class_weight':['balanced'],'tol':[1e-3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    514\n",
       "1     89\n",
       "Name: Recession_in_6mo, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xb\n",
    "X_train['Recession_in_6mo'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0.005, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "eval(classifier[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40352114426199837,\n",
       " 0.3782616908436191,\n",
       " 0.4293197848926318,\n",
       " 0.430237270192837,\n",
       " 0.3932180272971814]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV  \n",
    "for i in output_feature:\n",
    "    grid = GridSearchCV(svm.SVC(),param_grid,verbose=2,scoring='recall',cv=10)\n",
    "    grid.fit(X_train.iloc[:,1:7],y_train[i])\n",
    "    svmc=grid.best_estimator_\n",
    "    predicted_probability[i+\"_probability\"] = svmc.predict_proba(x_testing_data.iloc[:,1:7])[:,1]\n",
    "    past_predict[i+\"_probability\"]=svmc.predict_proba(X_train.iloc[:,1:7])[:,1]\n",
    "    test_prob[i+\"_probability\"]=svmc.predict_proba(X_test.iloc[:,1:7])[:,1]\n",
    "    filename = i+'.sv'\n",
    "    pickle.dump(svc_model, open(filename, 'wb'))\n",
    "      \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in output_feature:\n",
    "    svm_ac = {}\n",
    "    for x, y in [(x, y) for x in c for y in gamma]:\n",
    "        k = x, y\n",
    "        # initalize the'model' and passing the SVM Classifier with respect to C and gamma value\n",
    "        model = svm.SVC(C=x, kernel='rbf', gamma=y, probability=True,\n",
    "                        tol=1e-3,\n",
    "                        class_weight='balanced')\n",
    "        accuracy = cross_val_score(model, X_train.iloc[:,1:7], y_train[i], cv=10, scoring='recall')\n",
    "        svm_ac[k] = np.mean(accuracy)\n",
    "        print(\"\\n{:20} {:25}\".format('Parameter', 'Average accuracy'))\n",
    "        print('{}\\t{:25}'.format(k, np.mean(accuracy)))\n",
    "    print(f\"\\n----{i}------\")\n",
    "    acc_score = max(svm_ac, key=svm_ac.get)\n",
    "    print(f\"The best tuning parameter{acc_score}\")\n",
    "    svc_model = svm.SVC(C=acc_score[0], kernel='rbf', gamma=acc_score[1], probability=True,\n",
    "                        tol=1e-3, random_state=123,\n",
    "                        class_weight='balanced')\n",
    "   \n",
    "    # fitting the model with training data\n",
    "    svc_model.fit(X_train.iloc[:,1:7], y_train[i])\n",
    "    # predicting the model with the test data\n",
    "    y_predict = svc_model.predict(X_test.iloc[:,1:7])\n",
    "\n",
    "    # evaluating the accuracy with the ground truth and predicted value\n",
    "    model_acc = accuracy_score(y_test[i], y_predict)\n",
    "\n",
    "    print(\"Model Accuracy is: {}\".format(model_acc))\n",
    "    # classification_report((y_true, y_pred)\n",
    "    predicted_probability[i+\"_probability\"] = svc_model.predict_proba(x_testing_data.iloc[:,1:7])[:,1]\n",
    "    past_predict[i+\"_probability\"]=svc_model.predict_proba(X_train.iloc[:,1:7])[:,1]\n",
    "    test_prob[i+\"_probability\"]=svc_model.predict_proba(X_test.iloc[:,1:7])[:,1]\n",
    "    filename = i+'.sv'\n",
    "    pickle.dump(svc_model, open(filename, 'wb'))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predicted_probability['Date']= x_testing_data['Date'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "past_predict['Date']= X_train['Date'].tolist()\n",
    "test_prob['Date']=X_test['Date'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "past_predict.append(test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "past_predict.append(predicted_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "file=['Recession_in_6mo.xg','Recession_in_12mo.xg']\n",
    "\n",
    "for i in file:\n",
    "    svmc = pickle.load(open(i, 'rb'))\n",
    "    print(svmc.predict_proba(x[:,1:7])[:,1])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test=recession_data[recession_data['Date'] == '2007-02-01']\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(x_training_data, x_training_data.iloc[:,7:], test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier(max_depth=2000, random_state=0,class_weight='balanced')\n",
    "clf.fit(X_train.iloc[:,1:7], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_predict = clf.predict_proba(X_test.iloc[:,1:7])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/sebin/Desktop/companyandngo/website/house/sydney_new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[1:1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('/Users/sebin/Desktop/companyandngo/website/melboure_house.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "##logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[1:1000,:].to_csv('/Users/sebin/Desktop/companyandngo/website/1000_sydney.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "c = [1, 10, 100, 1000]\n",
    "gamma = [1e-3, 1e-4,.04]\n",
    "features = ['Date', 'Payrolls_3mo_vs_12mo', 'Effective_Fed_Funds_12_chg', 'CPI_All_Items_3_mo_annualised',\n",
    "            '10Y_Treasury_Rate_12_chg', '3M_10Y_Treasury_Spread', 'S&P_500_Index_12_chg','Recession_in_6mo','Recession_in_12mo','Recession_in_24mo']\n",
    "df = pd.read_csv('/Users/sebin/Desktop/companyandngo/Data/final_features.csv')[::-1]\n",
    "predicted_probability=pd.DataFrame()\n",
    "past_predict = pd.DataFrame()\n",
    "test_prob = pd.DataFrame()\n",
    "recession_data = df[features]\n",
    "#df_features.join(pd.get_dummies(df['Recession']))\n",
    "output_feature =['Recession_in_6mo','Recession_in_12mo','Recession_in_24mo']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_training_data=recession_data[recession_data['Date'] <= '2018-02-01']\n",
    "x_testing_data = recession_data[recession_data['Date'] >= '2018-02-01']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_training_data, x_training_data.iloc[:,7:], test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# implementing a Logistic Regression model with random hyperparameters\n",
    "LR = LogisticRegression(penalty='l1',dual=False,max_iter=110, solver='liblinear')\n",
    "LR.fit(X_train,Y_train)\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=110, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "# In[158]:\n",
    "\n",
    "\n",
    "#setting the parameters\n",
    "dual=[True,False]\n",
    "max_iter=[100,110,120,130,140]\n",
    "C = [1.0,1.5,2.0,2.5,3.0,3.5,4.0]\n",
    "param_grid = dict(dual=dual,max_iter=max_iter,C=C)\n",
    "\n",
    "\n",
    "# In[159]:\n",
    "\n",
    "\n",
    "#implementing a Grid search on our defined hyperparameters\n",
    "LR = LogisticRegression(penalty='l2')\n",
    "G_search = GridSearchCV(estimator=LR, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "import time\n",
    "\n",
    "starting_time = time.time()\n",
    "G_search_results = G_search.fit(X_train,Y_train)\n",
    "# Summarizing the  results\n",
    "print(\"Best accuracy: %f gained by using this set of parameters%s\" % (G_search_results.best_score_, G_search_results.best_params_))\n",
    "print(\"time of execution: \" + str((time.time() - starting_time)) + ' ms')\n",
    "\n",
    "\n",
    "# In[160]:\n",
    "\n",
    "\n",
    "#implementing a Random search on our defined hyperparameters\n",
    "R_search = RandomizedSearchCV(estimator=LR, param_distributions=param_grid, cv = 3, n_jobs=-1)\n",
    "starting_time = time.time()\n",
    "R_search_results = R_search.fit(X_train,Y_train)\n",
    "# Summarizing the  results\n",
    "print(\"Best accuracy: %f gained by using this set of parameters%s\" % (R_search_results.best_score_, R_search_results.best_params_))\n",
    "print(\"time of execution: \" + str((time.time() - starting_time)) + ' ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
